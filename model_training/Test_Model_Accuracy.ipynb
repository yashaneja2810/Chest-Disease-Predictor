{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b109b7",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5afdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install tensorflow matplotlib seaborn scikit-learn pillow -q\n",
    "\n",
    "print(\"‚úÖ All libraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33d423",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafa7acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Sklearn for metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c354e3c",
   "metadata": {},
   "source": [
    "## Step 3: Setup Kaggle API & Download Dataset\n",
    "\n",
    "**Note:** Replace with your Kaggle API token if different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Replace with your actual Kaggle API token\n",
    "KAGGLE_API_TOKEN = \"KGAT_2967f7dc8630bc7987580c2cf613c4db\"\n",
    "\n",
    "# Create kaggle.json file\n",
    "kaggle_credentials = {\n",
    "    \"username\": \"\",\n",
    "    \"key\": KAGGLE_API_TOKEN\n",
    "}\n",
    "\n",
    "# Create .kaggle directory\n",
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "\n",
    "# Write credentials\n",
    "kaggle_path = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "with open(kaggle_path, 'w') as f:\n",
    "    json.dump(kaggle_credentials, f)\n",
    "\n",
    "# Set correct permissions\n",
    "os.chmod(kaggle_path, 0o600)\n",
    "\n",
    "print(\"‚úÖ Kaggle API credentials configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a6d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the ChestX6 dataset\n",
    "print(\"‚¨áÔ∏è Downloading ChestX6 dataset from Kaggle...\\n\")\n",
    "\n",
    "!kaggle datasets download -d mohamedasak/chest-x-ray-6-classes-dataset\n",
    "\n",
    "# Unzip the dataset\n",
    "print(\"\\nüì¶ Extracting dataset...\")\n",
    "!unzip -q chest-x-ray-6-classes-dataset.zip -d dataset\n",
    "\n",
    "print(\"\\n‚úÖ Dataset downloaded and extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fcf46",
   "metadata": {},
   "source": [
    "## Step 4: Auto-Detect Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d357d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect the correct dataset structure\n",
    "print(\"üîç Auto-detecting dataset paths...\")\n",
    "\n",
    "possible_structures = [\n",
    "    ('dataset/chest-xray', 'train', 'val', 'test'),\n",
    "    ('dataset/chest-xray', 'train', 'validation', 'test'),\n",
    "    ('dataset', 'train', 'val', 'test'),\n",
    "    ('dataset', 'train', 'validation', 'test'),\n",
    "]\n",
    "\n",
    "BASE_DIR = None\n",
    "TRAIN_DIR = None\n",
    "VAL_DIR = None\n",
    "TEST_DIR = None\n",
    "\n",
    "for base, train, val, test in possible_structures:\n",
    "    train_path = os.path.join(base, train)\n",
    "    val_path = os.path.join(base, val)\n",
    "    test_path = os.path.join(base, test)\n",
    "\n",
    "    if os.path.exists(train_path):\n",
    "        BASE_DIR = base\n",
    "        TRAIN_DIR = train_path\n",
    "        VAL_DIR = val_path if os.path.exists(val_path) else None\n",
    "        TEST_DIR = test_path if os.path.exists(test_path) else None\n",
    "        print(f\"‚úÖ Found dataset structure!\")\n",
    "        print(f\"   Base: '{BASE_DIR}'\")\n",
    "        print(f\"   Train: {TRAIN_DIR} {'‚úì' if os.path.exists(TRAIN_DIR) else '‚úó'}\")\n",
    "        print(f\"   Val: {VAL_DIR} {'‚úì' if VAL_DIR and os.path.exists(VAL_DIR) else '‚úó'}\")\n",
    "        print(f\"   Test: {TEST_DIR} {'‚úì' if TEST_DIR and os.path.exists(TEST_DIR) else '‚úó'}\")\n",
    "        break\n",
    "\n",
    "if TEST_DIR is None or not os.path.exists(TEST_DIR):\n",
    "    raise Exception(\"‚ùå ERROR: Test directory not found!\")\n",
    "\n",
    "print(f\"\\nüìä Test Set Classes: {os.listdir(TEST_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12b2e2e",
   "metadata": {},
   "source": [
    "## Step 5: Upload Your Trained Model\n",
    "\n",
    "Upload `best_model_finetuned.h5` using the file browser on the left üìÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for user to upload the model\n",
    "import time\n",
    "\n",
    "model_file = 'best_model_finetuned.h5'\n",
    "\n",
    "print(\"‚è≥ Waiting for model upload...\")\n",
    "print(f\"Please upload '{model_file}' using the file browser (üìÅ) on the left\")\n",
    "print(\"\\nChecking every 5 seconds...\\n\")\n",
    "\n",
    "while not os.path.exists(model_file):\n",
    "    time.sleep(5)\n",
    "    print(\"‚è≥ Still waiting for model file...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Model file '{model_file}' detected!\")\n",
    "print(f\"File size: {os.path.getsize(model_file) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e7d35",
   "metadata": {},
   "source": [
    "## Step 6: Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "print(\"üì• Loading the fine-tuned model...\\n\")\n",
    "\n",
    "model = load_model('best_model_finetuned.h5')\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"\\nTotal Parameters: {model.count_params():,}\")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32443bb4",
   "metadata": {},
   "source": [
    "## Step 7: Create Test Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed502c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "CLASS_MODE = 'categorical'\n",
    "\n",
    "# Test data generator (only rescaling, no augmentation)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get class labels\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\nüìã Class Indices:\")\n",
    "print(test_generator.class_indices)\n",
    "print(f\"\\nTotal Test Images: {test_generator.samples}\")\n",
    "print(f\"Number of Classes: {len(class_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbe83e",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate Model on Test Set üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ca567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"üìä Evaluating model on test set...\\n\")\n",
    "print(\"This may take 2-5 minutes...\\n\")\n",
    "\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator)\n",
    "\n",
    "# Calculate F1 Score\n",
    "test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ TEST SET PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Accuracy:  {test_accuracy*100:.2f}%\")\n",
    "print(f\"‚úÖ Precision: {test_precision*100:.2f}%\")\n",
    "print(f\"‚úÖ Recall:    {test_recall*100:.2f}%\")\n",
    "print(f\"‚úÖ F1-Score:  {test_f1*100:.2f}%\")\n",
    "print(f\"‚úÖ Loss:      {test_loss:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare with expected accuracy\n",
    "expected_accuracy = 86.07\n",
    "difference = abs(test_accuracy*100 - expected_accuracy)\n",
    "\n",
    "if difference < 1.0:\n",
    "    print(f\"\\nüéâ VERIFIED! Accuracy matches expected {expected_accuracy}% ¬±1%\")\n",
    "elif difference < 3.0:\n",
    "    print(f\"\\n‚úÖ CLOSE! Accuracy is within {expected_accuracy}% ¬±3% (acceptable)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Accuracy differs from expected {expected_accuracy}% by {difference:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e10f38",
   "metadata": {},
   "source": [
    "## Step 9: Generate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ed740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print(\"üîÆ Generating predictions...\\n\")\n",
    "\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels,\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            annot_kws={'fontsize': 10})\n",
    "plt.title('Confusion Matrix - Test Set Performance', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix saved as 'test_confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786bfe5d",
   "metadata": {},
   "source": [
    "## Step 10: Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nüìã DETAILED CLASSIFICATION REPORT:\")\n",
    "print(\"=\"*70)\n",
    "report = classification_report(true_classes, predicted_classes,\n",
    "                                target_names=class_labels,\n",
    "                                digits=4)\n",
    "print(report)\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Per-class accuracy breakdown\n",
    "print(\"\\nüéØ PER-CLASS PERFORMANCE SUMMARY:\\n\")\n",
    "for i, label in enumerate(class_labels):\n",
    "    mask = true_classes == i\n",
    "    class_accuracy = accuracy_score(true_classes[mask], predicted_classes[mask])\n",
    "    class_count = np.sum(mask)\n",
    "    \n",
    "    # Visual indicator\n",
    "    if class_accuracy >= 0.95:\n",
    "        emoji = \"üü¢\"\n",
    "    elif class_accuracy >= 0.85:\n",
    "        emoji = \"üü°\"\n",
    "    elif class_accuracy >= 0.75:\n",
    "        emoji = \"üü†\"\n",
    "    else:\n",
    "        emoji = \"üî¥\"\n",
    "    \n",
    "    print(f\"{emoji} {label:20s}: {class_accuracy*100:6.2f}% ({class_count:4d} images)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e323e0",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "test_generator.reset()\n",
    "x_batch, y_batch = next(test_generator)\n",
    "predictions_batch = model.predict(x_batch)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "fig.suptitle('Sample Predictions on Test Set', fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(x_batch):\n",
    "        # Display image\n",
    "        ax.imshow(x_batch[i])\n",
    "\n",
    "        # Get prediction and true label\n",
    "        pred_class = np.argmax(predictions_batch[i])\n",
    "        true_class = np.argmax(y_batch[i])\n",
    "        confidence = predictions_batch[i][pred_class] * 100\n",
    "\n",
    "        pred_label = class_labels[pred_class]\n",
    "        true_label = class_labels[true_class]\n",
    "\n",
    "        # Color: green if correct, red if wrong\n",
    "        color = 'green' if pred_class == true_class else 'red'\n",
    "        marker = \"‚úì\" if pred_class == true_class else \"‚úó\"\n",
    "\n",
    "        ax.set_title(f'{marker} True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%',\n",
    "                    color=color, fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample predictions saved as 'test_sample_predictions.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0037b7",
   "metadata": {},
   "source": [
    "## Step 12: Per-Class Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze confidence scores per class\n",
    "print(\"üìä CONFIDENCE SCORE ANALYSIS\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, label in enumerate(class_labels):\n",
    "    # Get predictions for this class\n",
    "    class_mask = true_classes == i\n",
    "    class_predictions = predictions[class_mask]\n",
    "    \n",
    "    if len(class_predictions) > 0:\n",
    "        # Get confidence scores for correct predictions\n",
    "        correct_mask = predicted_classes[class_mask] == i\n",
    "        correct_confidences = class_predictions[correct_mask, i] * 100\n",
    "        \n",
    "        if len(correct_confidences) > 0:\n",
    "            avg_conf = np.mean(correct_confidences)\n",
    "            min_conf = np.min(correct_confidences)\n",
    "            max_conf = np.max(correct_confidences)\n",
    "            \n",
    "            print(f\"{label:20s}: Avg={avg_conf:6.2f}%  Min={min_conf:6.2f}%  Max={max_conf:6.2f}%\")\n",
    "        else:\n",
    "            print(f\"{label:20s}: No correct predictions\")\n",
    "    else:\n",
    "        print(f\"{label:20s}: No samples in test set\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad65597",
   "metadata": {},
   "source": [
    "## Step 13: Download Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3278e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import time\n",
    "\n",
    "# Download test results\n",
    "files_to_download = [\n",
    "    'test_confusion_matrix.png',\n",
    "    'test_sample_predictions.png',\n",
    "]\n",
    "\n",
    "print(\"‚¨áÔ∏è Downloading test result files...\\n\")\n",
    "\n",
    "for file in files_to_download:\n",
    "    if os.path.exists(file):\n",
    "        size = os.path.getsize(file) / (1024*1024)\n",
    "        print(f\"üì• {file} ({size:.2f} MB)\")\n",
    "        try:\n",
    "            files.download(file)\n",
    "            print(f\"‚úÖ Downloaded!\\n\")\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed: {str(e)}\\n\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Not found: {file}\\n\")\n",
    "\n",
    "print(\"‚úÖ Download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d2432",
   "metadata": {},
   "source": [
    "## üéâ Testing Complete!\n",
    "\n",
    "### Summary:\n",
    "- ‚úÖ Model loaded successfully\n",
    "- ‚úÖ Tested on complete test dataset\n",
    "- ‚úÖ Generated confusion matrix\n",
    "- ‚úÖ Detailed classification report created\n",
    "- ‚úÖ Sample predictions visualized\n",
    "\n",
    "### Expected Results:\n",
    "- **Overall Accuracy:** ~86%\n",
    "- **Best Classes:** Tuberculosis (100%), COVID-19 (94%), Emphysema (94%)\n",
    "- **Challenging Classes:** Pneumonia-Viral (55-60%)\n",
    "\n",
    "### If accuracy matches:\n",
    "Your model is **production-ready**! Place `best_model_finetuned.h5` in your backend as `chest_xray_model.h5` and start making predictions.\n",
    "\n",
    "### If accuracy differs significantly:\n",
    "- Check if model file was corrupted during download\n",
    "- Verify file size (~100-120 MB)\n",
    "- Re-download from Google Colab"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
